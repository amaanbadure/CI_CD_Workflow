name: Sacred ML Workflow CI/CD

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  train-and-evaluate:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.8'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run Sacred experiment
      run: python sacred_runner.py
      
    - name: Upload experiment logs
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: experiment-logs
        path: experiment_logs/
        retention-days: 14

    - name: Check experiment results
      run: |
        python - <<EOF
        import json
        import glob
        import sys
        import os
        
        try:
            # Get the latest run
            runs = glob.glob('experiment_logs/*/run.json')
            if not runs:
                print("No run.json files found!")
                sys.exit(1)
                
            latest_run = max(runs, key=lambda x: os.path.getctime(x))
            print(f"Reading results from: {latest_run}")
            
            with open(latest_run) as f:
                results = json.load(f)
                print(f"Results structure: {results.keys()}")
                
            # Try to get accuracy from different possible locations
            accuracy = None
            if 'info' in results and 'test_accuracy' in results['info']:
                accuracy = results['info']['test_accuracy']
            elif 'result' in results and isinstance(results['result'], dict) and 'test_accuracy' in results['result']:
                accuracy = results['result']['test_accuracy']
            elif 'result' in results and isinstance(results['result'], float):
                accuracy = results['result']
            
            if accuracy is None:
                print("Could not find test_accuracy in results!")
                sys.exit(1)
                
            print(f"Found accuracy: {accuracy}")
            
            # Changed threshold from 0.85 to 0.60
            if accuracy < 0.60:
                print(f'Accuracy {accuracy} below threshold 0.60')
                sys.exit(1)
            else:
                print(f'Accuracy {accuracy} meets or exceeds threshold 0.60')
                
        except Exception as e:
            print(f"Error processing results: {str(e)}")
            sys.exit(1)
        EOF